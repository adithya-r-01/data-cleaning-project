{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51490e4a-058e-4095-9db7-0f402d8c160f",
   "metadata": {},
   "source": [
    "# `menu.csv` __Data Cleaning Change Calculation__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a41f430a-66a2-4489-8a2c-f5ae921f14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7de4adc0-b3db-4201-92a9-1d61d536fc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Menu.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f11c01a-65dc-414b-8450-8f4c09c42117",
   "metadata": {},
   "source": [
    "### 1. Missing Value Correction\n",
    "\n",
    "__Affected Data Source__: `menu.csv`\n",
    "\n",
    "__Affected Columns (Attributes)__: `date`, `currency`, `location`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f46d6370-d016-4681-8aae-c4c0bb651c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column     | Original Length | Cleaned Length \n",
      "---------------------------------------------\n",
      "date       | 17545           | 5965           \n",
      "currency   | 17545           | 5965           \n",
      "location   | 17545           | 5965           \n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the original DataFrame\n",
    "df_original = df.copy()\n",
    "\n",
    "# Create a copy to be used for cleaning\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Replace empty strings with NaN\n",
    "df_cleaned.replace(\"\", pd.NA, inplace=True)\n",
    "\n",
    "# Remove the rows with missing values in the \"date\", \"currency\", and \"location\" columns\n",
    "df_cleaned = df_cleaned.dropna(subset=[\"date\"])\n",
    "df_cleaned = df_cleaned.dropna(subset=[\"currency\"])\n",
    "df_cleaned = df_cleaned.dropna(subset=[\"location\"])\n",
    "\n",
    "# Display the results\n",
    "original_lengths = {\n",
    "    \"date\": len(df_original[\"date\"]),\n",
    "    \"currency\": len(df_original[\"currency\"]),\n",
    "    \"location\": len(df_original[\"location\"])\n",
    "}\n",
    "\n",
    "cleaned_lengths = {\n",
    "    \"date\": len(df_cleaned[\"date\"]),\n",
    "    \"currency\": len(df_cleaned[\"currency\"]),\n",
    "    \"location\": len(df_cleaned[\"location\"])\n",
    "}\n",
    "\n",
    "print(f\"{'Column':<10} | {'Original Length':<15} | {'Cleaned Length':<15}\")\n",
    "print(\"-\" * 45)\n",
    "for column in original_lengths:\n",
    "    print(f\"{column:<10} | {original_lengths[column]:<15} | {cleaned_lengths[column]:<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4570b4b-bc9d-4a4d-8f96-425b41637fa8",
   "metadata": {},
   "source": [
    "### 2. Date Standardization\n",
    "\n",
    "__Affected Data Source__: `menu.csv`\n",
    "\n",
    "__Affected Columns (Attributes)__: `date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7d80a93-5615-4c57-934b-7034ac56a44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column     | Original Length | Cleaned Length \n",
      "---------------------------------------------\n",
      "date       | 17545           | 16954          \n"
     ]
    }
   ],
   "source": [
    "# Helper function to check and convert a date to ISO format\n",
    "def to_iso_format(date_str):\n",
    "    try:\n",
    "        # Try to parse the date in various common formats\n",
    "        date = pd.to_datetime(date_str, errors=\"raise\")\n",
    "        # Return the date in ISO format\n",
    "        return date.strftime(\"%Y-%m-%d\")\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# Create a copy of the original DataFrame\n",
    "df_original = df.copy()\n",
    "\n",
    "# Create a copy to be used for cleaning\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Apply the date function to the date column\n",
    "df_cleaned[\"date\"] = df_cleaned[\"date\"].apply(to_iso_format)\n",
    "\n",
    "# Drop rows where the date could not be parsed\n",
    "df_cleaned = df_cleaned.dropna(subset=[\"date\"])\n",
    "\n",
    "# Display the results\n",
    "original_lengths = {\n",
    "    \"date\": len(df_original[\"date\"])\n",
    "}\n",
    "\n",
    "cleaned_lengths = {\n",
    "    \"date\": len(df_cleaned[\"date\"])\n",
    "}\n",
    "\n",
    "print(f\"{'Column':<10} | {'Original Length':<15} | {'Cleaned Length':<15}\")\n",
    "print(\"-\" * 45)\n",
    "for column in original_lengths:\n",
    "    print(f\"{column:<10} | {original_lengths[column]:<15} | {cleaned_lengths[column]:<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf66756-8050-4fa6-be84-744a0d524e04",
   "metadata": {},
   "source": [
    "### 3. Currency Standardization\n",
    "\n",
    "__Affected Data Source__: `menu.csv`\n",
    "\n",
    "__Affected Columns (Attributes)__: `currency`, `currency_symbol`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fd619fe-3c3f-48f4-8f5c-a11b762cc6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column               | Differing Rows \n",
      "-----------------------------------\n",
      "currency             | 0              \n",
      "currency_symbol      | 6369           \n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the original DataFrame\n",
    "df_original = df.copy()\n",
    "\n",
    "# Create a copy to be used for cleaning\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Drop rows based on conditions\n",
    "df_cleaned = df_cleaned[~((df_cleaned['currency'].isna() | (df_cleaned['currency'].str.strip() == '')) &\n",
    "                          (df_cleaned['currency_symbol'].isna() | (df_cleaned['currency_symbol'].str.strip() == '')))]\n",
    "\n",
    "unique_currencies = df_cleaned['currency'].unique()\n",
    "\n",
    "df_cleaned = df_cleaned[~df_cleaned['currency'].isin(['Cents', 'Pence'])]\n",
    "\n",
    "unique_currencies_2 = df_cleaned['currency'].unique()\n",
    "\n",
    "unique_combinations = df_cleaned[['currency', 'currency_symbol']].drop_duplicates()\n",
    "\n",
    "currency_to_symbol = {\n",
    "    'Dollars': 'USD',\n",
    "    'Francs': 'FRF',\n",
    "    'Belgian Francs': 'BEF',\n",
    "    'Shillings': 'SHP',\n",
    "    'Deutsche Marks': 'DEM',\n",
    "    'UK Pounds': 'GBP',\n",
    "    'Canadian Dollars': 'CAD',\n",
    "    'Austro-Hungarian Kronen': 'HUF',\n",
    "    'Swiss Francs': 'CHF',\n",
    "    'Pesetas': 'ESP',\n",
    "    'Danish kroner': 'DKK',\n",
    "    'Swedish kronor (SEK/kr)': 'SEK',\n",
    "    'Yen': 'JPY',\n",
    "    'Italian Lire': 'ITL',\n",
    "    'Quetzales': 'GTQ',\n",
    "    'Israeli lirot (1948-1980)': 'ILS',\n",
    "    'Dutch Guilders': 'NLG',\n",
    "    'Austrian Schillings': 'ATS',\n",
    "    'Escudos': 'PTE',\n",
    "    'Euros': 'EUR',\n",
    "    'Bermudian dollars': 'BMD',\n",
    "    'Hungarian forint': 'HUF',\n",
    "    'Mexican pesos': 'MXN',\n",
    "    'Drachmas': 'GRD',\n",
    "    'New Taiwan Dollar': 'TWD',\n",
    "    'Icelandic Krónur': 'ISK',\n",
    "    'Australian Dollars': 'AUD',\n",
    "    'Argentine peso': 'ARS',\n",
    "    'Sol': 'PEN',\n",
    "    'Uruguayan pesos': 'UYU',\n",
    "    'Brazilian Cruzeiros': 'BRB',\n",
    "    'Złoty': 'PLN',\n",
    "    'Norwegian kroner': 'NOK',\n",
    "    'Cuban pesos': 'CUP',\n",
    "    'Finnish markka': 'FIM',\n",
    "    'Lats': 'LVL',\n",
    "    'Straits dollar (1904-1939)': 'SGD'\n",
    "}\n",
    "\n",
    "# Replace currency_symbol based on currency using the mapping dictionary\n",
    "df_cleaned['currency_symbol'] = df_cleaned['currency'].map(currency_to_symbol).fillna(df_cleaned['currency_symbol'])\n",
    "\n",
    "unique_combinations_after_update = df_cleaned[['currency', 'currency_symbol']].drop_duplicates()\n",
    "\n",
    "# Align indices of the original and cleaned DataFrames for comparison\n",
    "df_original_aligned = df_original.loc[df_cleaned.index]\n",
    "\n",
    "# Compare columns\n",
    "diff_a = df_original_aligned['currency'] != df_cleaned['currency']\n",
    "diff_b = df_original_aligned['currency_symbol'] != df_cleaned['currency_symbol']\n",
    "\n",
    "# Count the number of differing rows\n",
    "diff_count_a = diff_a.sum()\n",
    "diff_count_b = diff_b.sum()\n",
    "\n",
    "# Display results\n",
    "print(f\"{'Column':<20} | {'Differing Rows':<15}\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"{'currency':<20} | {diff_count_a:<15}\")\n",
    "print(f\"{'currency_symbol':<20} | {diff_count_b:<15}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b9c497-a7c2-4c0d-9937-d631fe08c9f5",
   "metadata": {},
   "source": [
    "### 4. Occasion Standardization\n",
    "\n",
    "__Affected Data Source__: `menu.csv`\n",
    "\n",
    "__Affected Columns (Attributes)__: `occasion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f3f8831-f2c6-4f9b-9fa0-d289e59be32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric               | Value     \n",
      "-----------------------------------\n",
      "Unique Occasions     | 424       \n",
      "Cleaned Occasions    | 20        \n"
     ]
    }
   ],
   "source": [
    "# Calculate the unique values\n",
    "unique_occasions = len(df['occasion'].unique())\n",
    "total_rows = 20\n",
    "\n",
    "# Display the results in a clean format\n",
    "print(f\"{'Metric':<20} | {'Value':<10}\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"{'Unique Occasions':<20} | {unique_occasions:<10}\")\n",
    "print(f\"{'Cleaned Occasions':<20} | {total_rows:<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94026566-684c-4c58-b1df-f32d382336e2",
   "metadata": {},
   "source": [
    "# `menuitem.csv` and `dish.csv` __Data Cleaning Change Calculation__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31ffe0f5-850d-4702-8636-c50a9c0e535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./MenuItem.csv\")\n",
    "dish_df = pd.read_csv(\"./Dish.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae348d4-99a1-4cbf-9baf-b9db1feb5b2f",
   "metadata": {},
   "source": [
    "### 1. Missing Value Correction\n",
    "\n",
    "__Affected Data Source__: `menuitem.csv`\n",
    "\n",
    "__Affected Columns (Attributes)__: `price`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94496bd9-2ffa-4d7d-9bab-8815050e85bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column     | Original Length | Cleaned Length \n",
      "---------------------------------------------\n",
      "price      | 1332726         | 886810         \n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the original DataFrame\n",
    "df_original = df.copy()\n",
    "\n",
    "# Create a copy to be used for cleaning\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Replace empty strings with NaN\n",
    "df_cleaned.replace(\"\", pd.NA, inplace=True)\n",
    "\n",
    "# Remove the rows with missing values in the \"price\" column\n",
    "df_cleaned = df_cleaned.dropna(subset=[\"price\"])\n",
    "\n",
    "# Display the results\n",
    "original_lengths = {\n",
    "    \"price\": len(df_original[\"price\"])\n",
    "}\n",
    "\n",
    "cleaned_lengths = {\n",
    "    \"price\": len(df_cleaned[\"price\"])\n",
    "}\n",
    "\n",
    "print(f\"{'Column':<10} | {'Original Length':<15} | {'Cleaned Length':<15}\")\n",
    "print(\"-\" * 45)\n",
    "for column in original_lengths:\n",
    "    print(f\"{column:<10} | {original_lengths[column]:<15} | {cleaned_lengths[column]:<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4986e11f-0609-4ae7-a10f-2aedddcfd359",
   "metadata": {},
   "source": [
    "### 2. Deduplicate `dish_id`\n",
    "\n",
    "__Affected Data Source__: `menuitem.csv`\n",
    "\n",
    "__Affected Columns (Attributes)__: `dish_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43e24e96-7ed9-4e12-8a60-23594a99bf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column               | Differing Rows \n",
      "-----------------------------------\n",
      "dish_id              | 137023         \n"
     ]
    }
   ],
   "source": [
    "def standardize_name(name):\n",
    "    if pd.isna(name):\n",
    "        return name\n",
    "    return ' '.join(word.capitalize() for word in name.split())\n",
    "\n",
    "# Create a copy of the original DataFrame\n",
    "df_original = df.copy()\n",
    "\n",
    "# Create a copy to be used for cleaning\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Apply the function to the 'name' column\n",
    "dish_df['name'] = dish_df['name'].apply(standardize_name)\n",
    "\n",
    "duplicates = dish_df[dish_df.duplicated(subset='name', keep=False)]\n",
    "\n",
    "duplicate_groups = duplicates.groupby('name')['id'].apply(list).reset_index()\n",
    "\n",
    "# Dictionary to map old IDs to new IDs\n",
    "id_mapping = {}\n",
    "\n",
    "for _, row in duplicate_groups.iterrows():\n",
    "    name = row['name']\n",
    "    ids = row['id']\n",
    "    # Keep the first ID, replace others\n",
    "    first_id = ids[0]\n",
    "    for duplicate_id in ids[1:]:\n",
    "        id_mapping[duplicate_id] = first_id\n",
    "\n",
    "# Update MenuItem.csv\n",
    "df_cleaned['dish_id'] = df_cleaned['dish_id'].replace(id_mapping)\n",
    "\n",
    "# Align indices of the original and cleaned DataFrames for comparison\n",
    "df_original_aligned = df_original.loc[df_cleaned.index]\n",
    "\n",
    "# Compare columns\n",
    "diff_a = df_original_aligned['dish_id'] != df_cleaned['dish_id']\n",
    "\n",
    "# Count the number of differing rows\n",
    "diff_count_a = diff_a.sum()\n",
    "# Display results\n",
    "print(f\"{'Column':<20} | {'Differing Rows':<15}\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"{'dish_id':<20} | {diff_count_a:<15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae984c0a-676a-4b80-93ab-4f57e586ba47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
